{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import matplotlib.transforms\n",
    "import csv\n",
    "import ast\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy\n",
    "from scipy.signal import oaconvolve\n",
    "import time\n",
    "import copy\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startfilename = \"acq_000058160.edf.csv\"\n",
    "numberOfFiles = 1\n",
    "fileoffset = 1234\n",
    "savemetrics = False\n",
    "\n",
    "AAnnopath = \"C:\\\\Users\\\\aaron\\\\OneDrive\\\\Dokumente\\\\Uni\\\\Studienarbeit\\\\automatische Annotationen\\\\\"\n",
    "MAnnopath = \"C:\\\\Users\\\\aaron\\\\OneDrive\\\\Dokumente\\\\Uni\\\\Studienarbeit\\\\manuelle Annotationen\\\\\"\n",
    "\n",
    "includepath = \"C:\\\\Users\\\\aaron\\\\OneDrive\\\\Dokumente\\\\Uni\\\\Studienarbeit\\\\includedFiles.csv\"\n",
    "path = \"\\\\\\\\vs-grp06.zih.tu-dresden.de\\\\gl4psgdata\\\\tsm-retro-lm\\\\\"\n",
    "\n",
    "saveMetricdir = 'C:\\\\Users\\\\aaron\\\\OneDrive\\\\Dokumente\\\\Uni\\\\Studienarbeit\\\\Metrics\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAnnofilenames = next(walk(MAnnopath), (None, None, []))[2] \n",
    "AAnnofilenames = next(walk(AAnnopath), (None, None, []))[2] \n",
    "startAtFileNr = AAnnofilenames.index(startfilename)+ fileoffset\n",
    "stopAtFileNr = startAtFileNr + numberOfFiles\n",
    "metricfilenames = next(walk(saveMetricdir), (None, None, []))[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds all LM that fullfill the AASM time requirements [5-90]s\n",
    "def findRecurringLM(annotation):\n",
    "    recurringLM = []\n",
    "    buffer = []\n",
    "    for m in range(len(annotation)-1): #collecting LM in buffer\n",
    "        if (annotation[m+1][0] - annotation[m][0] > 5*sampleFreq) and (annotation[m+1][0] - annotation[m][0] < 90*sampleFreq):\n",
    "            buffer.append(m)\n",
    "            if(m == len(annotation)-2): #last LM ist part of series\n",
    "                buffer.append(m+1)\n",
    "\n",
    "        elif len(buffer) !=0: #end of series \n",
    "            buffer.append(m)\n",
    "            recurringLM.append(buffer)\n",
    "            buffer = []\n",
    "            \n",
    "    if len(buffer) != 0: recurringLM.append(buffer)\n",
    "    return recurringLM\n",
    "    \n",
    "#flattens any list to 1D\n",
    "def flattenx(nested_list, regular_list):\n",
    "    \n",
    "    for ele in nested_list:\n",
    "        if type(ele) is list:\n",
    "            flattenx(ele, regular_list)\n",
    "        else:\n",
    "            regular_list.append(ele)\n",
    "    return regular_list\n",
    "\n",
    "def flatten(nested_list):\n",
    "    return flattenx(nested_list, regular_list = [])\n",
    "\n",
    "#finds the series that a certain LM is in \n",
    "def correspondingLMSeries(LMidx, LMSeries):\n",
    "    for Serie in LMSeries:\n",
    "        if(LMidx in Serie):\n",
    "            return Serie \n",
    "    return []\n",
    "\n",
    "#index of the annotation signal where given LM would fit \n",
    "def FNindex(LM, Annoc):\n",
    "    for idx in range(len(Annoc)):\n",
    "        if(LM [0] < Annoc[idx][1]):\n",
    "            return idx\n",
    "    else: return len(Annoc)\n",
    "    \n",
    "#calculates TP,FP,TN,FN transforming the annotation signals in one second segments\n",
    "def segmentwiseClasses(mAnno,aAnno):\n",
    "    mannoBuffer = []\n",
    "    for i in range(len(mAnno)):\n",
    "        mannoBuffer = np.append(mannoBuffer, np.zeros(mAnno[i][0] - len(mannoBuffer), dtype=int))\n",
    "        mannoBuffer = np.append(mannoBuffer, np.ones(mAnno[i][1] - len(mannoBuffer), dtype=int))\n",
    "    mannoBuffer = np.append(mannoBuffer, np.zeros(int(len(Sleepstage)*sampleFreq - len(mannoBuffer))))\n",
    "    \n",
    "    msecondBins = []\n",
    "    for s in range(len(Sleepstage)):\n",
    "        if(len(np.where(mannoBuffer[s*sampleFreq:(s+1)*sampleFreq] == 1)[0]) > 100):#more than 50%\n",
    "            msecondBins.append(1)\n",
    "            \n",
    "        else:\n",
    "            msecondBins.append(0)\n",
    "    aannoBuffer = []\n",
    "    for i in range(len(aAnno)):\n",
    "        aannoBuffer = np.append(aannoBuffer, np.zeros(aAnno[i][0] - len(aannoBuffer), dtype=int))\n",
    "        aannoBuffer = np.append(aannoBuffer, np.ones(aAnno[i][1] - len(aannoBuffer), dtype=int))\n",
    "    aannoBuffer = np.append(aannoBuffer, np.zeros(int(len(Sleepstage)*sampleFreq - len(aannoBuffer))))\n",
    "    \n",
    "    asecondBins = []\n",
    "    for s in range(len(Sleepstage)):\n",
    "        if(len(np.where(aannoBuffer[s*sampleFreq:(s+1)*sampleFreq] == 1)[0]) > 100):#more than 50%\n",
    "            asecondBins.append(1)\n",
    "            \n",
    "        else:\n",
    "            asecondBins.append(0)\n",
    "    TP,FP,TN,FN = 0,0,0,0\n",
    "    for s in range(len(msecondBins)):\n",
    "        if(msecondBins[s] == 1 and asecondBins[s] == 1):\n",
    "            TP += 1\n",
    "        elif(msecondBins[s] == 0 and asecondBins[s] == 1):\n",
    "            FP += 1\n",
    "        elif(msecondBins[s] == 1 and asecondBins[s] == 0):\n",
    "            FN += 1\n",
    "        elif(msecondBins[s] == 0 and asecondBins[s] == 0):\n",
    "            TN += 1\n",
    "    return TP,FP,TN,FN\n",
    "\n",
    "def calcClassicalMetrics(TP,FP,TN,FN):\n",
    "    F1 = 2*TP/(2*TP+FP+FN) if TP+FP+FN != 0 else math.inf\n",
    "    p0 = (TP+TN)/(TP+TN+FP+FN) if TP+TN+FP+FN != 0 else math.inf\n",
    "    pe = ((TP+FN)*(TP+FP)+(TN+FP)*(TN+FN))/(TP+TN+FP+FN)**2 if TP+TN+FP+FN != 0 else math.inf\n",
    "    k = (p0-pe)/(1-pe) if 1-pe != 0 else math.inf\n",
    "    Spez = TN/(TN+FP) if TN+FP != 0 else math.inf\n",
    "    Prec = TP/(TP+FP) if TP+FP != 0 else math.inf\n",
    "    Sens = TP/(TP+FN) if TP+FN != 0 else math.inf\n",
    "    Acc = (TP+TN)/(TP+TN+FP+FN) if TP+TN+FP+FN != 0 else math.inf\n",
    "    NPV = TN/(TN+FN) if TN+FN != 0 else math.inf\n",
    "\n",
    "    return F1,k,Spez,Prec,Sens,Acc,NPV\n",
    "\n",
    "\n",
    "\n",
    "#plots two annotaitonsignals with shape [[starLM1,endLM1],[starLM2,endLM2],...]\n",
    "def plotAnnotation(signals, labels,  lightOff, lightOn, plotwindow):\n",
    "    fig = plt.figure(figsize=(16,2))\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    plt.margins(x=0.1, y=0.1)\n",
    "    for sidx, signal in enumerate(signals):\n",
    "\n",
    "        annoBuffer = np.zeros(lightOff, dtype=int)\n",
    "        \n",
    "        for i in range(len(signal)):\n",
    "            annoBuffer = np.append(annoBuffer, np.zeros(signal[i][0] - len(annoBuffer), dtype=int))\n",
    "            annoBuffer = np.append(annoBuffer, np.ones(signal[i][1] - len(annoBuffer), dtype=int))\n",
    "        annoBuffer = np.append(annoBuffer, np.zeros(lightOn - len(annoBuffer)))\n",
    "        annoBuffer = [\"kein LM\" if annoSample == 0 else \"LM\" for annoSample in annoBuffer]\n",
    "        \n",
    "        #offset of signals for better view\n",
    "        offset = matplotlib.transforms.Affine2D().translate(0, 3*sidx)\n",
    "        \n",
    "        shadow_transform = fig.axes[0].transData + offset\n",
    "        plt.plot(annoBuffer[plotwindow[0]:plotwindow[1]], label = labels[sidx], transform = shadow_transform)\n",
    "        \n",
    "    plt.xticks(np.arange(0,(plotwindow[1]-plotwindow[0])*11/10, (plotwindow[1]-plotwindow[0])/10))\n",
    "    plt.xlabel(\"Zeit in ms\")\n",
    "    plt.legend(loc = \"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customname = \"Xto1\"\n",
    "\n",
    "\n",
    "with open(includepath , \"r\", newline='') as csvfile:\n",
    "\n",
    "    content = csv.reader(csvfile,  delimiter=';', quotechar='\"')\n",
    "    strings = list(content)\n",
    "    data = []\n",
    "    for e in strings:\n",
    "        data.append(e)\n",
    "\n",
    "includefiles = flatten(data)\n",
    "\n",
    "\n",
    "totalstarttime = time.time()\n",
    "for filename in [\"acq_058268826.edf\"]:#example to test against\n",
    "#for filename in [file for file in includefiles[startAtFileNr:stopAtFileNr] if file+ \".csv\" not in metricfilenames]:\n",
    "    filestarttime = time.time()\n",
    "    print(\"working on file \" + filename)\n",
    "    print(\"Nr: \"+ str(includefiles.index(filename)) + \" noch \" +str(stopAtFileNr - includefiles.index(filename)))\n",
    "    f = pyedflib.EdfReader(path + filename)\n",
    "    Sleepstage = f.readSignal(2)\n",
    "    sampleFreq = int(f.getSampleFrequency(0))\n",
    "    f.close()\n",
    "\n",
    "    #reading csv back to list\n",
    "    with open(MAnnopath + filename + \".csv\" , \"r\") as csvfile:\n",
    "        content = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        strings = list(content)\n",
    "        if(len(strings) == 0 or strings[0][0] == \" \"):\n",
    "            continue\n",
    "        mAnno = []\n",
    "        for e in strings[0]:\n",
    "            mAnno.append(eval(e))\n",
    "\n",
    "\n",
    "    mAnno = [LMS for LMS in mAnno if Sleepstage[int(LMS[0]/200)] != 0]\n",
    "\n",
    "    #custom signals\n",
    "    mAnno = [[10000,15000],[15500,15800],[17000,17200],[18100,19000]]\n",
    "    aAnno = [[9000,18500],[19200,20300],[21400,22500],[23600,24000]] \n",
    "    #aAnno = [[10000,15000],[15500,15800],[17000,17200],[17800,19000]]#,[20000,21000]]\n",
    "\n",
    "    '''\n",
    "    calculating metrics as usual -refer to MetricfromCSV\n",
    "    '''\n",
    "    matchings = [] # contains indices (one for each signal) of LM that overlap\n",
    "    for m in range(len(mAnno)): \n",
    "        for a in range(len(aAnno)):\n",
    "            if (mAnno[m][0] < aAnno[a][1]) and ((mAnno[m][1] > aAnno[a][0])): #any overlap\n",
    "                totalOverlap = (min(mAnno[m][1],aAnno[a][1]) - max(mAnno[m][0],aAnno[a][0]))\n",
    "                smallerLMArea = (min(mAnno[m][1]-mAnno[m][0],aAnno[a][1]-aAnno[a][0]))\n",
    "                matchings.append([m,a])\n",
    "    uniqueMAnno = set()\n",
    "\n",
    "    OneToXList = [idx for idx in [match[0] for match in matchings] if idx in uniqueMAnno or uniqueMAnno.add(idx)] \n",
    "    OneToX = len(OneToXList)+len(set(OneToXList))\n",
    "\n",
    "    uniqueAAnno = set()\n",
    "    XToOneList = [idx for idx in [match[1] for match in matchings] if idx in uniqueAAnno or uniqueAAnno.add(idx)] \n",
    "    XToOne = len(XToOneList)+len(set(XToOneList))\n",
    "    \n",
    "    \n",
    "    # indices of mAnno - LM that are manually annotated but not automatically annotated\n",
    "    FNList = []\n",
    "    for idx in range(len(mAnno)):\n",
    "        if idx not in [i[0] for i in matchings]:\n",
    "            FNList.append(idx)\n",
    "    # indices of aAnno - LM that are automatically annotated but not manually annotated\n",
    "    FPList = []\n",
    "    for idx in range(len(aAnno)):\n",
    "        if idx not in [i[1] for i in matchings]:\n",
    "            FPList.append(idx)\n",
    "            \n",
    "    FN = len(FNList)\n",
    "    FP = len(FPList)\n",
    "    TP = len(matchings) - len(XToOneList) - len(OneToXList)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    TN are counted by a rising edge in either signal that is not within a LM of the other signal\n",
    "    when both signals rise together the time prior of on of the Signals counts as TN \n",
    "    (assuming there are no single Samples counting as TN)\n",
    "    when one signal is rising as the other one is falling there is no TN '''\n",
    "    within = 0\n",
    "    for mLM in mAnno:\n",
    "         within = within + [mLM[0] > aLM[0] and mLM[0] <= aLM[1] for aLM in aAnno].count(True) \n",
    "\n",
    "    for aLM in aAnno:\n",
    "         within = within + [aLM[0] >= mLM[0] and aLM[0] <= mLM[1] for mLM in mAnno].count(True) \n",
    "\n",
    "    TN = len(mAnno)+len(aAnno) - within + 1\n",
    "    \n",
    "    SF1,Sk,SSpez,SPrec,SSens,SAcc,SNPV = 0,0,0,0,0,0,0 #calcClassicalMetrics(STP,SFP,STN,SFN)\n",
    "    \n",
    "    F1,k,Spez,Prec,Sens,Acc,NPV = calcClassicalMetrics(TP,FP,TN,FN)\n",
    "    \n",
    "    #removes the XtoOne and OneToX multiple matchings from list so that only the first and the last matched of each LM are in new List\n",
    "    currentMatch = [-1,-1]\n",
    "\n",
    "    cleanedMatchingsForFirsts = []\n",
    "    for match in matchings:\n",
    "        if currentMatch[0] != match[0] and currentMatch[1] != match[1]:\n",
    "            cleanedMatchingsForFirsts.append(match)\n",
    "        currentMatch = match\n",
    "\n",
    "\n",
    "    cleanedMatchingsForLasts = []\n",
    "    for i in range(len(matchings)):\n",
    "        if i+1 < len(matchings):\n",
    "            nextMatch = matchings[i+1] \n",
    "        else: cleanedMatchingsForLasts.append(matchings[i])\n",
    "        if nextMatch[0] != matchings[i][0] and nextMatch[1] != matchings[i][1]:\n",
    "            cleanedMatchingsForLasts.append(matchings[i])\n",
    "\n",
    "\n",
    "    LMStartDistribution = []\n",
    "    for match in cleanedMatchingsForFirsts:\n",
    "        LMStartDistribution.append(mAnno[match[0]][0]-aAnno[match[1]][0])\n",
    "    #plt.hist(LMStartDistribution, label='start time distribution')\n",
    "\n",
    "    LMEndDistribution = []\n",
    "    for match in cleanedMatchingsForLasts:\n",
    "        LMEndDistribution.append(mAnno[match[0]][1]-aAnno[match[1]][1])\n",
    "\n",
    "    LMStartDistribution_mean = np.mean(LMStartDistribution)\n",
    "    LMEndDistribution_mean = np.mean(LMEndDistribution)\n",
    "\n",
    "    LMStartDistribution_std = np.std(LMStartDistribution)\n",
    "    LMEndDistribution_std = np.std(LMEndDistribution)\n",
    "    \n",
    "    mLMSeries = findRecurringLM(mAnno)\n",
    "    aLMSeries = findRecurringLM(aAnno)\n",
    "    \n",
    "    aLMcount = len(aAnno)\n",
    "    mLMcount = len(mAnno)\n",
    "\n",
    "    mPLMcount = sum(len(series) for series in mLMSeries)\n",
    "    aPLMcount = sum(len(series) for series in aLMSeries)\n",
    "    \n",
    "    \n",
    "    realALMSeries = [series for series in aLMSeries if len(series)>=4]\n",
    "    realMLMSeries = [series for series in mLMSeries if len(series)>=4]\n",
    "    \n",
    "    realaPLMcount = len(flatten(realALMSeries))\n",
    "    realmPLMcount = len(flatten(realMLMSeries))\n",
    "    \n",
    "    TST = len([stage for stage in Sleepstage if stage != 0]) # in seconds\n",
    "\n",
    "    mPLMph = realmPLMcount/TST if TST != 0 else math.inf\n",
    "    aPLMph = realaPLMcount/TST if TST != 0 else math.inf\n",
    "    \n",
    "    mFourRecurringViolations = len(mLMSeries) - len(realMLMSeries)\n",
    "    aFourRecurringViolations = len(aLMSeries) - len(realALMSeries)\n",
    "    \n",
    "    #mistakes in Costfunctional that have been accounted for \n",
    "    overcountedA = []\n",
    "    undercountedM = []\n",
    "    undercountedA = []\n",
    "\n",
    "    # Number of PLM that are were falsely counted because of FP\n",
    "    overcountedPLM = 0\n",
    "\n",
    "    for realALMSerie in realALMSeries:\n",
    "        buffer = []\n",
    "        FPcounter = 0\n",
    "        for FP in FPList:\n",
    "            if FP in realALMSerie: \n",
    "                FPcounter += 1\n",
    "                buffer.append(FP)\n",
    "\n",
    "        if(len(realALMSerie)-FPcounter>=4):\n",
    "\n",
    "            overcountedPLM += FPcounter\n",
    "            if(FPcounter != 0):\n",
    "                overcountedA.append(buffer)\n",
    "\n",
    "        else:\n",
    "            overcountedPLM += len(realALMSerie)\n",
    "            overcountedA.append(realALMSerie)\n",
    "    overcountedA = flatten(overcountedA)\n",
    "    \n",
    "    \n",
    "    # first entry of OneToXMmatches is the mAnno index that the OnetoX was matched to (rest of entries)\n",
    "    OneToXMmatches = []\n",
    "\n",
    "    for One in set(OneToXList):\n",
    "        buffer = [One]\n",
    "        for match in matchings:\n",
    "            if(match[0]== One):\n",
    "                buffer.append(match[1])\n",
    "        OneToXMmatches.append(buffer)\n",
    "\n",
    "    #OneToX Overcount where a OneToX match is responsible for changing the PLM number without changing the 4 rule \n",
    "    OneToXOvercount = 0\n",
    "\n",
    "    for rSeries in realALMSeries:\n",
    "        buffer = []\n",
    "        LMcounter = 0 \n",
    "        for rLM in rSeries:#count the onetox responsible for each series \n",
    "            if(rLM in flatten([matches[1:] for matches in OneToXMmatches])):\n",
    "                LMcounter += 1\n",
    "                buffer.append(rLM)\n",
    "\n",
    "        if(len(rSeries)-LMcounter >= 4): # case onetox did not change the 4 rule \n",
    "            OneToXOvercount += LMcounter\n",
    "            if(LMcounter != 0):\n",
    "                overcountedA.append(buffer)\n",
    "        else: #change due to 4 rule \n",
    "            OneToXOvercount += len(rSeries)\n",
    "            overcountedA.append(rSeries)\n",
    "    overcountedA = flatten(overcountedA)\n",
    "    \n",
    "    #TP that are in realALMSerie while corresponding match is not in realMLMSeries\n",
    "    TPTimeViolationsOvercount = 0 \n",
    "\n",
    "    #regular \n",
    "    for realALMSerie in realALMSeries:\n",
    "        buffer = []\n",
    "\n",
    "        for LM in realALMSerie:\n",
    "            for match in matchings:#find match\n",
    "                if(match[0] not in flatten(OneToXList) and match[1] == LM and match[0] not in flatten(correspondingLMSeries(LM, mLMSeries))):\n",
    "                    buffer.append(match[1])\n",
    "        if(len(realALMSerie)-len(buffer) < 4):\n",
    "            overcountedA.append(realALMSerie)\n",
    "            TPTimeViolationsOvercount += len(realALMSerie)\n",
    "\n",
    "        else:\n",
    "            overcountedA.append(buffer)\n",
    "            TPTimeViolationsOvercount += len(buffer)\n",
    "    overcountedA = flatten(overcountedA)\n",
    "   \n",
    "    \n",
    "    #Xto1 matching that falsely reduces PLM count\n",
    "    XToOneAmatches = []\n",
    "\n",
    "    for One in set(XToOneList):\n",
    "        buffer = [One]\n",
    "        for match in matchings:\n",
    "            if(match[1] == One):\n",
    "                buffer.append(match[0])\n",
    "        XToOneAmatches.append(buffer)\n",
    "\n",
    "    XToOneUndercount = 0\n",
    "\n",
    "    for rSeries in realMLMSeries:\n",
    "        LMcounter = 0 \n",
    "        for rLM in rSeries:#count the xto1 responsible for each series \n",
    "            if(rLM in flatten([matches[1:] for matches in XToOneAmatches])):\n",
    "                LMcounter += 1\n",
    "        if(len(rSeries)-LMcounter >= 4): # case onetox did not change the 4 rule \n",
    "            XToOneUndercount += LMcounter\n",
    "            if(LMcounter != 0):\n",
    "                undercountedM.append(rLM)\n",
    "        else: #change due to 4 rule \n",
    "            XToOneUndercount += len(rSeries)\n",
    "            undercountedM.append(rSeries)\n",
    "    undercountedM = flatten(undercountedM)\n",
    "    \n",
    "    \n",
    "    \n",
    "    TPTimeViolationsUndercount = 0 \n",
    "    #regular \n",
    "    for realMLMSerie in realMLMSeries:\n",
    "        buffer = []\n",
    "\n",
    "        for LM in realMLMSerie:\n",
    "            for match in matchings:#find match\n",
    "                if(match[1] not in flatten(XToOneList) and match[0] == LM and match[1] not in flatten(correspondingLMSeries(LM, aLMSeries))):\n",
    "                    buffer.append(match[1])\n",
    "        if(len(realMLMSerie)-len(buffer) < 4):\n",
    "            undercountedM.append(realMLMSerie)\n",
    "            TPTimeViolationsUndercount += len(realMLMSerie)\n",
    "\n",
    "        else:\n",
    "            undercountedA.append(buffer)\n",
    "            TPTimeViolationsUndercount += len(buffer)\n",
    "\n",
    "    undercountedM = flatten(undercountedM)\n",
    "    undercountedA = flatten(undercountedA)\n",
    "    \n",
    "    # Number of PLM that are were not counted beacuse of FN\n",
    "    undercountedPLM = 0\n",
    "\n",
    "    aAnnoc = copy.deepcopy(aAnno)\n",
    "\n",
    "    oldRecurring = [Serie for Serie in findRecurringLM(aAnnoc) if len(Serie) >= 4]\n",
    "    oldLen = len(flatten(oldRecurring))\n",
    "\n",
    "    for FN in FNList:\n",
    "        aAnnoc.insert(FNindex(mAnno[FN],aAnnoc),mAnno[FN])\n",
    "    newRecurring = [Serie for Serie in findRecurringLM(aAnnoc) if len(Serie) >= 4]\n",
    "    undercountedPLM =  len(flatten(newRecurring)) - oldLen\n",
    "\n",
    "    for Serie in newRecurring:\n",
    "        FNcounter = 0\n",
    "        FNbuffer = []\n",
    "        for indx,newLM in enumerate(aAnnoc):\n",
    "            if( newLM in mAnno and mAnno.index(newLM) in FNList):\n",
    "                FNcounter += 1\n",
    "                FNbuffer.append(mAnno.index(newLM))\n",
    "                \n",
    "        if(len(Serie)-FNcounter<4): #Series founded\n",
    "            for LM in Serie:\n",
    "                undercountedM.append(mAnno.index(aAnnoc[LM]))\n",
    "        else:\n",
    "            undercountedM.append(FNbuffer)\n",
    "                        \n",
    "    undercountedM = flatten(undercountedM)\n",
    "    \n",
    "    doubleOverCount = len(overcountedA)-len(set(overcountedA))\n",
    "    doubleUnderCount = len(undercountedM)-len(set(undercountedM))+len(undercountedA)-len(set(undercountedA))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #cost functional \n",
    "    K = overcountedPLM + OneToXOvercount + TPTimeViolationsOvercount - doubleOverCount + (XToOneUndercount + TPTimeViolationsUndercount + undercountedPLM - doubleUnderCount)  \n",
    "    Krel = K/realmPLMcount if realmPLMcount != 0 else math.inf\n",
    "    metrics = [TP,TN,FP,FN,F1,k,Spez,Prec,Sens,Acc,NPV,SF1,Sk,SSpez,SPrec,SSens,SAcc,SNPV,mLMcount,aLMcount,mPLMcount,aPLMcount,realmPLMcount,realaPLMcount,OneToX,XToOne,LMStartDistribution_mean,LMEndDistribution_mean,LMStartDistribution_std,LMEndDistribution_std,mFourRecurringViolations,aFourRecurringViolations, doubleOverCount,doubleUnderCount,overcountedPLM,OneToXOvercount,TPTimeViolationsOvercount,XToOneUndercount,TPTimeViolationsUndercount,undercountedPLM,K, Krel,mPLMph,aPLMph]\n",
    "    metrics.append(\"custom\"+ customname)\n",
    "     \n",
    "    if(savemetrics):\n",
    "        with open(\"custom\"+ customname +  \".csv\", \"w\") as csvfile:\n",
    "            swriter = csv.writer(csvfile, delimiter=',')\n",
    "            swriter.writerow(metrics)\n",
    "    fileendtime = time.time()\n",
    "    print(\"runningtime: \"+'{:5.3f}s'.format(fileendtime-filestarttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotAnnotation([mAnno,aAnno],[\"manuelle Annotation\",\"automatische Annotation\"] ,  8000,28000, [8000,28000])\n",
    "\n",
    "displayMetric(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
